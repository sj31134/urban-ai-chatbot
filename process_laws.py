#!/usr/bin/env python3
"""
ë„ì‹œì •ë¹„ì‚¬ì—… ë²•ë ¹ ë¬¸ì„œ ì¼ê´„ ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸
data/laws ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  ë²•ë ¹ ë¬¸ì„œë¥¼ Neo4j ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ì— ë¡œë“œ
"""

# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
import os  # ìš´ì˜ì²´ì œ ê´€ë ¨ ê¸°ëŠ¥
import sys  # ì‹œìŠ¤í…œ ê´€ë ¨ ê¸°ëŠ¥
import logging  # ë¡œê·¸ ê¸°ë¡
from pathlib import Path  # ê²½ë¡œ ì²˜ë¦¬
from datetime import datetime  # ë‚ ì§œ/ì‹œê°„ ì²˜ë¦¬
from typing import List, Dict, Any  # íƒ€ì… íŒíŠ¸

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = os.path.dirname(os.path.abspath(__file__))  # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬
sys.path.insert(0, project_root)  # ì‹œìŠ¤í…œ ê²½ë¡œì— ì¶”ê°€

# í”„ë¡œì íŠ¸ ë‚´ë¶€ ëª¨ë“ˆ import
from src.graph.legal_graph import LegalGraphManager  # Neo4j ê·¸ë˜í”„ ê´€ë¦¬ì
from src.rag.document_processor import LegalDocumentProcessor  # ë¬¸ì„œ ì²˜ë¦¬ê¸°
from dotenv import load_dotenv  # í™˜ê²½ë³€ìˆ˜ ë¡œë“œ

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()  # .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ì½ê¸°

# ë¡œê¹… ì„¤ì •
logging.basicConfig(  # ë¡œê¹… ê¸°ë³¸ ì„¤ì •
    level=logging.INFO,  # INFO ë ˆë²¨ ë¡œê¹…
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',  # ë¡œê·¸ í˜•ì‹
    handlers=[  # í•¸ë“¤ëŸ¬ ì„¤ì •
        logging.FileHandler('logs/document_processing.log', encoding='utf-8'),  # íŒŒì¼ ë¡œê·¸
        logging.StreamHandler()  # ì½˜ì†” ë¡œê·¸
    ]
)
logger = logging.getLogger(__name__)  # í˜„ì¬ ëª¨ë“ˆìš© ë¡œê±° ìƒì„±


class LawDocumentBatchProcessor:
    """ë²•ë ¹ ë¬¸ì„œ ë°°ì¹˜ ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, data_directory: str = "data/laws"):
        """
        ë°°ì¹˜ ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        
        Args:
            data_directory: ë²•ë ¹ ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
        """
        self.data_directory = Path(data_directory)  # ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ ê°ì²´
        self.graph_manager = None  # ê·¸ë˜í”„ ê´€ë¦¬ì ì´ˆê¸°í™”
        self.processor = None  # ë¬¸ì„œ ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        self.supported_extensions = ['.pdf', '.docx', '.doc']  # ì§€ì›í•˜ëŠ” íŒŒì¼ í™•ì¥ì
        
    def initialize_components(self) -> bool:
        """ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸ”§ ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™” ì¤‘...")
            
            # Neo4j ê·¸ë˜í”„ ê´€ë¦¬ì ì´ˆê¸°í™”
            self.graph_manager = LegalGraphManager()  # ê·¸ë˜í”„ ê´€ë¦¬ì ìƒì„±
            logger.info("âœ… Neo4j ê·¸ë˜í”„ ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ")
            
            # ë¬¸ì„œ ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
            self.processor = LegalDocumentProcessor(self.graph_manager)  # ë¬¸ì„œ ì²˜ë¦¬ê¸° ìƒì„±
            logger.info("âœ… ë¬¸ì„œ ì²˜ë¦¬ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            
            return True  # ì„±ê³µ ë°˜í™˜
            
        except Exception as e:  # ì˜ˆì™¸ ë°œìƒ ì‹œ
            logger.error(f"âŒ ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")  # ì—ëŸ¬ ë¡œê·¸
            return False  # ì‹¤íŒ¨ ë°˜í™˜
    
    def scan_documents(self) -> List[Path]:
        """ì§€ì›í•˜ëŠ” ë²•ë ¹ ë¬¸ì„œ íŒŒì¼ ìŠ¤ìº”"""
        logger.info(f"ğŸ“‚ ë¬¸ì„œ ìŠ¤ìº” ì‹œì‘: {self.data_directory}")
        
        document_files = []  # ë¬¸ì„œ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
        
        if not self.data_directory.exists():  # ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´
            logger.error(f"âŒ ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.data_directory}")
            return document_files  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        
        # ì§€ì›í•˜ëŠ” í™•ì¥ìë¥¼ ê°€ì§„ íŒŒì¼ ê²€ìƒ‰
        for file_path in self.data_directory.iterdir():  # ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  íŒŒì¼ì— ëŒ€í•´
            if file_path.is_file() and file_path.suffix.lower() in self.supported_extensions:  # ì§€ì›í•˜ëŠ” íŒŒì¼ì´ë©´
                # ì‹œìŠ¤í…œ íŒŒì¼ ì œì™¸
                if not file_path.name.startswith('.') and not file_path.name.startswith('~'):
                    document_files.append(file_path)  # ë¬¸ì„œ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                    logger.info(f"ğŸ“„ ë°œê²¬ëœ ë¬¸ì„œ: {file_path.name}")
        
        logger.info(f"ğŸ“Š ì´ {len(document_files)}ê°œì˜ ë²•ë ¹ ë¬¸ì„œ ë°œê²¬")
        return document_files  # ë¬¸ì„œ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    
    def clear_existing_data(self) -> bool:
        """ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì„ íƒì‚¬í•­)"""
        try:
            logger.info("ğŸ—‘ï¸ ê¸°ì¡´ ê·¸ë˜í”„ ë°ì´í„° ì‚­ì œ ì¤‘...")
            
            # ëª¨ë“  ë…¸ë“œì™€ ê´€ê³„ ì‚­ì œ
            delete_query = "MATCH (n) DETACH DELETE n"  # ëª¨ë“  ë…¸ë“œ ì‚­ì œ ì¿¼ë¦¬
            self.graph_manager.execute_query(delete_query)  # ì¿¼ë¦¬ ì‹¤í–‰
            
            logger.info("âœ… ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ")
            return True  # ì„±ê³µ ë°˜í™˜
            
        except Exception as e:  # ì˜ˆì™¸ ë°œìƒ ì‹œ
            logger.error(f"âŒ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨: {e}")  # ì—ëŸ¬ ë¡œê·¸
            return False  # ì‹¤íŒ¨ ë°˜í™˜
    
    def process_document_file(self, file_path: Path) -> Dict[str, Any]:
        """ê°œë³„ ë¬¸ì„œ íŒŒì¼ ì²˜ë¦¬"""
        logger.info(f"ğŸ“– ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘: {file_path.name}")
        
        start_time = datetime.now()  # ì²˜ë¦¬ ì‹œì‘ ì‹œê°„
        
        try:
            # íŒŒì¼ í¬ê¸° í™•ì¸
            file_size = file_path.stat().st_size  # íŒŒì¼ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
            logger.info(f"ğŸ“ íŒŒì¼ í¬ê¸°: {file_size:,} bytes")
            
            # ë¬¸ì„œ ì²˜ë¦¬ ì‹¤í–‰
            result = self.processor.process_document(str(file_path))  # ë¬¸ì„œ ì²˜ë¦¬
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time = (datetime.now() - start_time).total_seconds()  # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            
            # ê²°ê³¼ ì •ë³´ ì¶”ê°€
            result.update({
                "file_name": file_path.name,  # íŒŒì¼ëª…
                "file_size": file_size,  # íŒŒì¼ í¬ê¸°
                "processing_time": processing_time,  # ì²˜ë¦¬ ì‹œê°„
                "processed_at": datetime.now().isoformat()  # ì²˜ë¦¬ ì‹œê°„
            })
            
            if result.get("success", False):  # ì„±ê³µí•œ ê²½ìš°
                logger.info(f"âœ… ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ: {file_path.name} ({processing_time:.2f}ì´ˆ)")
                logger.info(f"ğŸ“Š ì²˜ë¦¬ëœ ì¡°ë¬¸ ìˆ˜: {result.get('articles_count', 0)}ê°œ")
            else:  # ì‹¤íŒ¨í•œ ê²½ìš°
                logger.error(f"âŒ ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: {file_path.name} - {result.get('error', 'Unknown error')}")
            
            return result  # ì²˜ë¦¬ ê²°ê³¼ ë°˜í™˜
            
        except Exception as e:  # ì˜ˆì™¸ ë°œìƒ ì‹œ
            processing_time = (datetime.now() - start_time).total_seconds()  # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            error_result = {  # ì—ëŸ¬ ê²°ê³¼ ìƒì„±
                "success": False,
                "error": str(e),
                "file_name": file_path.name,
                "processing_time": processing_time,
                "processed_at": datetime.now().isoformat()
            }
            
            logger.error(f"âŒ ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {file_path.name} - {e}")
            return error_result  # ì—ëŸ¬ ê²°ê³¼ ë°˜í™˜
    
    def process_all_documents(self, clear_existing: bool = False) -> Dict[str, Any]:
        """ëª¨ë“  ë²•ë ¹ ë¬¸ì„œ ì¼ê´„ ì²˜ë¦¬"""
        logger.info("ğŸš€ ë²•ë ¹ ë¬¸ì„œ ì¼ê´„ ì²˜ë¦¬ ì‹œì‘")
        
        start_time = datetime.now()  # ì „ì²´ ì²˜ë¦¬ ì‹œì‘ ì‹œê°„
        
        # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì„ íƒì‚¬í•­)
        if clear_existing:  # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì˜µì…˜ì´ ì¼œì ¸ ìˆìœ¼ë©´
            if not self.clear_existing_data():  # ì‚­ì œ ì‹¤íŒ¨ ì‹œ
                return {"success": False, "error": "Failed to clear existing data"}
        
        # ë¬¸ì„œ íŒŒì¼ ìŠ¤ìº”
        document_files = self.scan_documents()  # ë¬¸ì„œ íŒŒì¼ ìŠ¤ìº”
        
        if not document_files:  # ë¬¸ì„œ íŒŒì¼ì´ ì—†ìœ¼ë©´
            logger.warning("âš ï¸ ì²˜ë¦¬í•  ë²•ë ¹ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {"success": False, "error": "No documents found to process"}
        
        # ì²˜ë¦¬ ê²°ê³¼ ì €ì¥
        results = {  # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
            "total_files": len(document_files),  # ì´ íŒŒì¼ ìˆ˜
            "processed_files": [],  # ì²˜ë¦¬ëœ íŒŒì¼ ë¦¬ìŠ¤íŠ¸
            "failed_files": [],  # ì‹¤íŒ¨í•œ íŒŒì¼ ë¦¬ìŠ¤íŠ¸
            "success_count": 0,  # ì„±ê³µ ê°œìˆ˜
            "error_count": 0,  # ì‹¤íŒ¨ ê°œìˆ˜
            "total_articles": 0,  # ì´ ì¡°ë¬¸ ìˆ˜
            "processing_start": start_time.isoformat(),  # ì²˜ë¦¬ ì‹œì‘ ì‹œê°„
        }
        
        # ê° ë¬¸ì„œ íŒŒì¼ ì²˜ë¦¬
        for i, file_path in enumerate(document_files, 1):  # ê° ë¬¸ì„œ íŒŒì¼ì— ëŒ€í•´
            logger.info(f"ğŸ“ˆ ì§„í–‰ë¥ : {i}/{len(document_files)} ({i/len(document_files)*100:.1f}%)")
            
            result = self.process_document_file(file_path)  # ë¬¸ì„œ íŒŒì¼ ì²˜ë¦¬
            
            if result.get("success", False):  # ì„±ê³µí•œ ê²½ìš°
                results["processed_files"].append(result)  # ì²˜ë¦¬ëœ íŒŒì¼ì— ì¶”ê°€
                results["success_count"] += 1  # ì„±ê³µ ê°œìˆ˜ ì¦ê°€
                results["total_articles"] += result.get("articles_count", 0)  # ì´ ì¡°ë¬¸ ìˆ˜ ëˆ„ì 
            else:  # ì‹¤íŒ¨í•œ ê²½ìš°
                results["failed_files"].append(result)  # ì‹¤íŒ¨í•œ íŒŒì¼ì— ì¶”ê°€
                results["error_count"] += 1  # ì‹¤íŒ¨ ê°œìˆ˜ ì¦ê°€
        
        # ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        total_time = (datetime.now() - start_time).total_seconds()  # ì´ ì²˜ë¦¬ ì‹œê°„
        results.update({
            "processing_end": datetime.now().isoformat(),  # ì²˜ë¦¬ ì¢…ë£Œ ì‹œê°„
            "total_processing_time": total_time,  # ì´ ì²˜ë¦¬ ì‹œê°„
            "success": results["success_count"] > 0  # ì „ì²´ ì„±ê³µ ì—¬ë¶€
        })
        
        # ìµœì¢… ê²°ê³¼ ë¡œê·¸
        logger.info("ğŸ“Š == ë²•ë ¹ ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ ==")
        logger.info(f"âœ… ì„±ê³µ: {results['success_count']}ê°œ")
        logger.info(f"âŒ ì‹¤íŒ¨: {results['error_count']}ê°œ")  
        logger.info(f"ğŸ“„ ì´ ì¡°ë¬¸ ìˆ˜: {results['total_articles']}ê°œ")
        logger.info(f"â±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
        
        return results  # ìµœì¢… ê²°ê³¼ ë°˜í™˜
    
    def get_processing_summary(self) -> Dict[str, Any]:
        """ì²˜ë¦¬ ìš”ì•½ ì •ë³´ ì¡°íšŒ"""
        try:
            # ê·¸ë˜í”„ í†µê³„ ì¡°íšŒ
            stats_query = """
            CALL db.labels() YIELD label
            WITH collect(label) as labels
            UNWIND labels as label
            CALL apoc.cypher.run('MATCH (n:' + label + ') RETURN count(n) as count', {}) YIELD value
            RETURN label, value.count as count
            """
            
            # ê°„ë‹¨í•œ í†µê³„ ì¿¼ë¦¬ë¡œ ëŒ€ì²´
            simple_stats = {
                "laws": self.graph_manager.execute_query("MATCH (l:Law) RETURN count(l) as count")[0]["count"],
                "articles": self.graph_manager.execute_query("MATCH (a:Article) RETURN count(a) as count")[0]["count"],
                "sections": self.graph_manager.execute_query("MATCH (s:Section) RETURN count(s) as count")[0]["count"]
            }
            
            return simple_stats  # í†µê³„ ë°˜í™˜
            
        except Exception as e:  # ì˜ˆì™¸ ë°œìƒ ì‹œ
            logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}  # ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ—ï¸ ë„ì‹œì •ë¹„ì‚¬ì—… ë²•ë ¹ ë¬¸ì„œ ì¼ê´„ ì²˜ë¦¬ ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    # ë°°ì¹˜ ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
    processor = LawDocumentBatchProcessor()  # ë°°ì¹˜ ì²˜ë¦¬ê¸° ìƒì„±
    
    # ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™”
    if not processor.initialize_components():  # ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ
        print("âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        sys.exit(1)  # í”„ë¡œê·¸ë¨ ì¢…ë£Œ
    
    # ì‚¬ìš©ì ì…ë ¥: ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì—¬ë¶€
    clear_data = input("\nê¸°ì¡´ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ê³  ìƒˆë¡œ ë¡œë“œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").lower().strip()
    clear_existing = clear_data in ['y', 'yes', 'ì˜ˆ', 'ã…‡']  # ì‚­ì œ ì—¬ë¶€ ê²°ì •
    
    if clear_existing:  # ì‚­ì œë¥¼ ì„ íƒí•œ ê²½ìš°
        print("âš ï¸ ê¸°ì¡´ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ê³  ìƒˆë¡œ ë¡œë“œí•©ë‹ˆë‹¤.")
    else:  # ì‚­ì œí•˜ì§€ ì•ŠëŠ” ê²½ìš°
        print("â„¹ï¸ ê¸°ì¡´ ë°ì´í„°ë¥¼ ìœ ì§€í•˜ê³  ìƒˆ ë°ì´í„°ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.")
    
    # ë¬¸ì„œ ì²˜ë¦¬ ì‹¤í–‰
    print("\nğŸš€ ë²•ë ¹ ë¬¸ì„œ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    results = processor.process_all_documents(clear_existing=clear_existing)  # ë¬¸ì„œ ì¼ê´„ ì²˜ë¦¬
    
    # ì²˜ë¦¬ ê²°ê³¼ ì¶œë ¥
    if results["success"]:  # ì„±ê³µí•œ ê²½ìš°
        print(f"\nâœ… ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"ğŸ“Š ì„±ê³µ: {results['success_count']}ê°œ ë¬¸ì„œ")
        print(f"ğŸ“„ ì´ {results['total_articles']}ê°œ ì¡°ë¬¸ ë¡œë“œë¨")
        
        if results["error_count"] > 0:  # ì‹¤íŒ¨í•œ íŒŒì¼ì´ ìˆëŠ” ê²½ìš°
            print(f"âš ï¸ ì‹¤íŒ¨: {results['error_count']}ê°œ ë¬¸ì„œ")
            print("\nì‹¤íŒ¨í•œ íŒŒì¼ë“¤:")
            for failed in results["failed_files"]:  # ì‹¤íŒ¨í•œ íŒŒì¼ë“¤ ì¶œë ¥
                print(f"  - {failed['file_name']}: {failed['error']}")
        
        # ê·¸ë˜í”„ í†µê³„ ì¶œë ¥
        print("\nğŸ“ˆ ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ í˜„í™©:")
        try:
            stats = processor.get_processing_summary()  # ì²˜ë¦¬ ìš”ì•½ ì¡°íšŒ
            for key, value in stats.items():  # í†µê³„ í•­ëª© ì¶œë ¥
                print(f"  - {key}: {value:,}ê°œ")
        except Exception as e:  # í†µê³„ ì¡°íšŒ ì‹¤íŒ¨ ì‹œ
            print(f"  í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            
    else:  # ì‹¤íŒ¨í•œ ê²½ìš°
        print(f"\nâŒ ì²˜ë¦¬ ì‹¤íŒ¨: {results.get('error', 'Unknown error')}")
        
    print(f"\nâ±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„: {results.get('total_processing_time', 0):.2f}ì´ˆ")
    print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")


if __name__ == "__main__":  # ìŠ¤í¬ë¦½íŠ¸ê°€ ì§ì ‘ ì‹¤í–‰ë  ë•Œ
    main()  # ë©”ì¸ í•¨ìˆ˜ í˜¸ì¶œ 